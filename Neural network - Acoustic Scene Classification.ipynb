{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, ReLU\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "data_aug = np.load('/content/drive/My Drive/dataset/data_aug.npy', allow_pickle=False, fix_imports=False)\n",
    "data_label_aug = np.load('/content/drive/My Drive/dataset/data_label_aug.npy', allow_pickle=False, fix_imports=False)\n",
    "\n",
    "data_test = np.load('/content/drive/My Drive/dataset/data_test.npy', allow_pickle=False, fix_imports=False)\n",
    "data_test_label = np.load('/content/drive/My Drive/dataset/data_test_label.npy', allow_pickle=False, fix_imports=False)\n",
    "\n",
    "\n",
    "train_data = data_aug #[0:88920]\n",
    "train_labels = data_label_aug #[0:88920]\n",
    "\n",
    "test_data = data_test\n",
    "test_labels = data_test_label\n",
    "\n",
    "LABELS = 'beach bus cafe/restaurant car city_center forest_path grocery_store home library metro_station office park residential_area train tram'.split() #Метки для распознавания\n",
    "NUM_CLASSES = len(LABELS)\n",
    "\n",
    "# векторизируем метки\n",
    "train_labels = to_categorical(train_labels, num_classes = NUM_CLASSES)\n",
    "test_labels = to_categorical(test_labels, num_classes = NUM_CLASSES)\n",
    "\n",
    "print('train_data.shape', train_data.shape)\n",
    "print('test_data.shape', test_data.shape)\n",
    "print()\n",
    "\n",
    "print('train_labels.shape', train_labels.shape)\n",
    "print('test_labels.shape', test_labels.shape)\n",
    "print('----------------------')\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_cnn(features_shape, num_classes): #Создаём модель сети\n",
    "    numF = 32\n",
    "\n",
    "    x = Input(name='inputs', shape=features_shape, dtype='float32')\n",
    "    o = x\n",
    "    o = BatchNormalization(name='block1_norm')(o)\n",
    "    \n",
    "    o = Conv2D(numF, (3, 3), padding='same', activation='relu', name='block1_conv', kernel_regularizer = regularizers.l2(0.00025), input_shape=features_shape)(o)\n",
    "    o = BatchNormalization(name='block2_norm')(o)\n",
    "    o = Conv2D(numF, (3, 3), padding='same', activation='relu', name='block2_conv', kernel_regularizer = regularizers.l2(0.00025))(o)\n",
    "    o = BatchNormalization(name='block3_norm')(o)\n",
    "    \n",
    "    o = MaxPooling2D((3, 3), strides=(2,2), padding='same', name='block1_pool')(o)\n",
    "    \n",
    "    o = Conv2D(2*numF, (3, 3), padding='same', activation='relu',  name='block3_conv', kernel_regularizer = regularizers.l2(0.00025))(o)\n",
    "    o = BatchNormalization(name='block4_norm')(o)\n",
    "    o = Conv2D(2*numF, (3, 3), padding='same', activation='relu',  name='block4_conv', kernel_regularizer = regularizers.l2(0.00025))(o)\n",
    "    o = BatchNormalization(name='block5_norm')(o)\n",
    "    \n",
    "    o = MaxPooling2D((3, 3), strides=(2,2), padding='same', name='block2_pool')(o)\n",
    "    \n",
    "    o = Conv2D(4*numF, (3, 3), padding='same', activation='relu',  name='block5_conv', kernel_regularizer = regularizers.l2(0.00025))(o)\n",
    "    o = BatchNormalization(name='block6_norm')(o)\n",
    "    o = Conv2D(4*numF, (3, 3), padding='same', activation='relu',  name='block6_conv', kernel_regularizer = regularizers.l2(0.00025))(o)\n",
    "    o = BatchNormalization(name='block7_norm')(o)\n",
    "    \n",
    "    o = MaxPooling2D((3, 3), strides=(2,2), padding='same', name='block3_pool')(o)\n",
    "    \n",
    "    o = Conv2D(8*numF, (3, 3), padding='same', activation='relu',  name='block7_conv', kernel_regularizer = regularizers.l2(0.00025))(o)\n",
    "    o = BatchNormalization(name='block8_norm')(o)\n",
    "    o = Conv2D(8*numF, (3, 3), padding='same', activation='relu',  name='block8_conv', kernel_regularizer = regularizers.l2(0.00025))(o)\n",
    "    o = BatchNormalization(name='block9_norm')(o)\n",
    "    \n",
    "    o = AveragePooling2D(pool_size =(16,6))(o)\n",
    "    o = Dropout(0.5)(o)\n",
    "    o = Flatten()(o)\n",
    "    o = Dense(15, activation='softmax', name='pred', kernel_regularizer = regularizers.l2(0.005))(o)\n",
    "\n",
    "    Model(inputs=x, outputs=o).summary()\n",
    "    \n",
    "    return Model(inputs=x, outputs=o)\n",
    "\n",
    "\n",
    "INPUT_SHAPE = (128,42,2) #Размер входной матрицы. Зависит от параметров спектрограммы\n",
    "BATCH = 128 #Размер пачки\n",
    "EPOCHS = 12 #Кол-во эпох\n",
    "LABELS = 'beach bus cafe/restaurant car city_center forest_path grocery_store home library metro_station office park residential_area train tram'.split() #Метки для распознавания\n",
    "NUM_CLASSES = len(LABELS)\n",
    "\n",
    "\n",
    "print('train_data.shape', train_data.shape)\n",
    "print('test_data.shape', test_data.shape)\n",
    "print()\n",
    "\n",
    "print('train_labels.shape', train_labels.shape)\n",
    "print('test_labels.shape', test_labels.shape)\n",
    "print('----------------------')\n",
    "print()\n",
    " \n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.03, momentum=0.8, decay = 0.0, nesterov = False)\n",
    "\n",
    "model = deep_cnn(INPUT_SHAPE, NUM_CLASSES) #Загружаем созданную модель\n",
    "model.compile(optimizer=sgd, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc']) #Выбор алгоритма оптимизации и функции ошибки\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 2:\n",
    "        return 0.03\n",
    "    elif epoch >= 2 and epoch < 4:\n",
    "        return 0.03*0.2\n",
    "    elif epoch >= 4 and epoch < 6:\n",
    "        return 0.03*0.2*0.2\n",
    "    elif epoch >= 6 and epoch < 8:\n",
    "        return 0.03*0.2*0.2\n",
    "    elif epoch >= 8 and epoch < 15:\n",
    "        return 0.03*0.2*0.2*0.2\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "my_callbacks = [LearningRateScheduler(scheduler),\n",
    "                EarlyStopping(monitor='val_acc', patience=4)] #Рання остановка  mode='max', restore_best_weights=True\n",
    "\n",
    "test_images = test_data\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs = 15,\n",
    "                    batch_size = BATCH,\n",
    "                    shuffle = True,\n",
    "                    verbose = 0,\n",
    "                    callbacks = my_callbacks,\n",
    "                    validation_data = (test_data, test_labels))\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Потери на этапе обучения')\n",
    "plt.plot(epochs, val_loss, 'b', label='Потери на этапе проверки')\n",
    "plt.title('Потери обучения и проверки')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Потери')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "plt.clf()\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, history.history['acc'], 'bo', label = 'Точность на этапе обучени' )\n",
    "plt.plot(epochs, history.history['val_acc'], 'b', label = 'Точность на этапе проверки')\n",
    "plt.title('Точность обучающих и проверочных данных')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Точность')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "for i in range (0,len(loss)):\n",
    "    print('loss')\n",
    "    print(i+1, ' эпоха: ', loss[i], sep='')\n",
    "print()\n",
    "\n",
    "for i in range (0,len(loss)):\n",
    "    print('val_loss')\n",
    "    print(i+1, ' эпоха: ', val_loss[i], sep='')\n",
    "print()\n",
    "\n",
    "for i in range (0,len(acc)):\n",
    "    print('acc')\n",
    "    print(i+1, ' эпоха: ', acc[i], sep='')\n",
    "print()\n",
    "\n",
    "for i in range (0,len(acc)):\n",
    "    print('val_acc')\n",
    "    print(i+1, ' эпоха: ', val_acc[i], sep='')\n",
    "\n",
    "\n",
    "\n",
    "test_images = test_data\n",
    "y_true = data_test_label\n",
    "classes = LABELS\n",
    "y_pred = model.predict(test_images)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\n",
    "\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    " \n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "\n",
    "plt.clf()\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Правильные метки')\n",
    "plt.xlabel('Проверочные метки')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
